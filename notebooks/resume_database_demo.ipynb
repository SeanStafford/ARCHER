{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Database Demo\n",
    "\n",
    "This notebook demonstrates the usage of `ResumeDocumentArchive` and `ResumeDatabase` for analyzing resume content.\n",
    "\n",
    "**Two complementary interfaces:**\n",
    "- **ResumeDocumentArchive**: Rich structured access (preserves hierarchy, sections, formatting)\n",
    "- **ResumeDatabase**: Fast SQL queries (flattened items table, cross-resume search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from archer.contexts.templating import (\n",
    "    ResumeDocumentArchive,\n",
    "    ResumeDatabase,\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "RESUME_ARCHIVE_PATH = Path(os.getenv(\"RESUME_ARCHIVE_PATH\"))\n",
    "DB_PATH = RESUME_ARCHIVE_PATH / \"structured\" / \"database\" / \"resumes.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: ResumeDocumentArchive (Structured Access)\n",
    "\n",
    "Load all resumes into memory with preserved structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load archive in plaintext mode (good for analysis)\n",
    "archive = ResumeDocumentArchive(archive_path=RESUME_ARCHIVE_PATH)\n",
    "archive.load(mode=\"available\", format_mode=\"plaintext\")\n",
    "print(f\"Loaded {len(archive.documents)} resumes into a ResumeDocumentArchive object\")\n",
    "\n",
    "# Access a specific resume\n",
    "sample_resume = \"Res202507_MLOps_Revature\"\n",
    "doc = archive.documents[sample_resume]\n",
    "print(doc.table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section: Experience (work_history)\n",
      "\n",
      "First subsection (work_experience):\n",
      "  Company: Booz Allen Hamilton\n",
      "  Title: Engineering and Physical Sciences Researcher\n",
      "  Items: 5 bullets\n",
      "  Projects: 2 nested projects\n"
     ]
    }
   ],
   "source": [
    "# Access section data (preserves hierarchy)\n",
    "section = doc.sections[4]  # Experience (work_history)\n",
    "print(f\"Section: {section.name} ({section.section_type})\")\n",
    "print(f\"\\nFirst subsection (work_experience):\")\n",
    "subsection = section.data[\"subsections\"][0]\n",
    "print(f\"  Company: {subsection['company']}\")\n",
    "print(f\"  Title: {subsection['title']}\")\n",
    "print(f\"  Items: {len(subsection['items'])} bullets\")\n",
    "print(f\"  Projects: {len(subsection['projects'])} nested projects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 2: Build Database (One-Time)\n\nFlatten all resume content into a queryable SQLite database.\n\n> **Tip**: You can also build the database from the command line using:\n> ```bash\n> python scripts/build_resume_database.py\n> ```"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database built: 4415 items\n"
     ]
    }
   ],
   "source": [
    "# Build database from archive (deletes existing DB)\n",
    "db = ResumeDatabase.from_documents(\n",
    "    documents=list(archive.documents.values()),\n",
    "    db_path=DB_PATH\n",
    ")\n",
    "\n",
    "# Count total items\n",
    "total_items = db.query(\"SELECT COUNT(*) as count FROM items\")[0][\"count\"]\n",
    "print(f\"Database built: {total_items} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Query Database (Fast, Persistent)\n",
    "\n",
    "Load existing database and run SQL queries.\n",
    "\n",
    "> Note: You do not have to rerun this cell if you already ran the above cell in this notebook.\n",
    "Similarly, you do not have to run the above cell if you have ever run it before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database loaded from disk\n"
     ]
    }
   ],
   "source": [
    "# Load existing database (fast - no parsing needed)\n",
    "db = ResumeDatabase(DB_PATH)\n",
    "print(\"Database loaded from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total skills: 2280\n",
      "\n",
      "First 5 skills:\n",
      "  - Python... (from Res202506_SenMathLibEng_NVIDIA)\n",
      "  - Bash... (from Res202506_SenMathLibEng_NVIDIA)\n",
      "  - C++... (from Res202506_SenMathLibEng_NVIDIA)\n",
      "  - MATLAB... (from Res202506_SenMathLibEng_NVIDIA)\n",
      "  - Wolfram/Mathematica... (from Res202506_SenMathLibEng_NVIDIA)\n"
     ]
    }
   ],
   "source": [
    "# Get all skills\n",
    "skills = db.get_all_skills()\n",
    "print(f\"Total skills: {len(skills)}\")\n",
    "print(f\"\\nFirst 5 skills:\")\n",
    "for skill in skills[:5]:\n",
    "    print(f\"  - {skill['item_text'][:50]}... (from {skill['resume_name']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total work bullets: 1844\n",
      "\n",
      "First bullet:\n",
      "  Resume: Res202506_SenMathLibEng_NVIDIA\n",
      "  Company: None\n",
      "  Title: None\n",
      "  Type: project\n",
      "  Text: Led development of domain-specific benchmark spanning CPUs, GPUs and ASICs...\n"
     ]
    }
   ],
   "source": [
    "# Get all work bullets\n",
    "bullets = db.get_all_bullets()\n",
    "print(f\"Total work bullets: {len(bullets)}\")\n",
    "print(f\"\\nFirst bullet:\")\n",
    "bullet = bullets[0]\n",
    "print(f\"  Resume: {bullet['resume_name']}\")\n",
    "print(f\"  Company: {bullet['company']}\")\n",
    "print(f\"  Title: {bullet['job_title']}\")\n",
    "print(f\"  Type: {bullet['subsection_type']}\")\n",
    "print(f\"  Text: {bullet['item_text'][:80]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 ML-related bullets\n",
      "\n",
      "First 3:\n",
      "  - [Florida State University] Forged lasting cross-institutional collaborations across 5 r...\n",
      "  - [Florida State University] Forged lasting cross-institutional collaborations across 5 p...\n",
      "  - [Florida State University] Forged lasting collaborations across multi-functional teams ...\n"
     ]
    }
   ],
   "source": [
    "# Custom SQL query: Find all ML-related bullets\n",
    "ml_bullets = db.query(\n",
    "    \"SELECT * FROM items WHERE item_text LIKE ? AND subsection_type IN (?, ?)\",\n",
    "    (\"%machine learning%\", \"work_experience\", \"project\")\n",
    ")\n",
    "print(f\"Found {len(ml_bullets)} ML-related bullets\\n\")\n",
    "print(\"First 3:\")\n",
    "for bullet in ml_bullets[:3]:\n",
    "    print(f\"  - [{bullet['company']}] {bullet['item_text'][:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items from skill_categories sections: 1335\n",
      "\n",
      "Sample categories:\n",
      "  [Languages] Python\n",
      "  [Languages] Bash\n",
      "  [Languages] C++\n",
      "  [Languages] MATLAB\n",
      "  [Languages] Wolfram/Mathematica\n"
     ]
    }
   ],
   "source": [
    "# Query by section type\n",
    "skill_categories = db.get_items_by_section_type(\"skill_categories\")\n",
    "print(f\"Items from skill_categories sections: {len(skill_categories)}\")\n",
    "print(f\"\\nSample categories:\")\n",
    "for item in skill_categories[:5]:\n",
    "    print(f\"  [{item['subsection_name']}] {item['item_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bullets from Booz Allen: 194\n",
      "\n",
      "First 3:\n",
      "  work_experience: Cut LLM training sessions from 1 month to \\ a day by scaling...\n",
      "  work_experience: Enabled client to train LLM to a loss that would have otherw...\n",
      "  work_experience: Grew team LLM capabilities by building custom PyTorch models...\n"
     ]
    }
   ],
   "source": [
    "# Query bullets from specific company\n",
    "booz_bullets = db.query(\n",
    "    \"SELECT * FROM items WHERE company = ?\",\n",
    "    (\"Booz Allen Hamilton\",)\n",
    ")\n",
    "print(f\"Bullets from Booz Allen: {len(booz_bullets)}\")\n",
    "print(f\"\\nFirst 3:\")\n",
    "for bullet in booz_bullets[:3]:\n",
    "    proj = f\" [{bullet['project_name']}]\" if bullet['project_name'] else \"\"\n",
    "    print(f\"  {bullet['subsection_type']}{proj}: {bullet['item_text'][:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items from MoE project: 46\n",
      "  - Performed original scaling studies on MoE models, for which empirical scaling be...\n",
      "  - Pushed client training to a loss that would have otherwise cost 6 compute budget...\n",
      "  - Performed original scaling studies on MoE models, for which empirical scaling be...\n",
      "  - Pushed client training to a loss that would have otherwise cost 6 compute budget...\n",
      "  - Performed original scaling studies on MoE models, for which empirical scaling be...\n",
      "  - Pushed client training to a loss that would have otherwise cost 6 compute budget...\n",
      "  - Performed original scaling studies on MoE models, for which empirical scaling be...\n",
      "  - Pushed client training to a loss that would have otherwise cost 6 compute budget...\n",
      "  - Performed original scaling studies on MoE models, for which empirical scaling be...\n",
      "  - Pushed client training to loss that would have otherwise cost 6\\ compute budget...\n",
      "  - Performed original scaling studies on MoE models, for which empirical scaling be...\n",
      "  - Pushed client training to loss that would have otherwise cost 6\\ compute budget...\n",
      "  - Performed original scaling studies on MoE models, for which empirical scaling be...\n",
      "  - Pushed client training to loss that would have otherwise cost 6\\ compute budget...\n",
      "  - Performed original scaling studies on MoE models, for which empirical scaling be...\n",
      "  - Pushed client training to loss that would have otherwise cost 6\\ compute budget...\n",
      "  - Performed original scaling studies on MoE models, for which empirical scaling be...\n",
      "  - Pushed client training to a loss that would have otherwise cost 6 compute budget...\n",
      "  - Performed original scaling studies on MoE models, for which empirical scaling be...\n",
      "  - Pushed client training to loss that would have otherwise cost 6\\ compute budget...\n",
      "  - Performed original scaling studies on MoE models, for which empirical scaling be...\n",
      "  - Enabled client's massive LLM pretraining to reach loss that would have required ...\n",
      "  - Performed original scaling studies on MoE models, for which empirical scaling be...\n",
      "  - Pushed client training to a loss that would have otherwise cost 6 compute budget...\n",
      "  - Performed original scaling studies on MoE models, for which empirical scaling be...\n",
      "  - My hyperparameter specification enabled client's massive LLM pretraining to reac...\n",
      "  - Performed original scaling studies on MoE models, for which empirical scaling be...\n",
      "  - Pushed client training to loss that would have otherwise cost 6\\ compute budget...\n",
      "  - Performed original scaling studies on MoE models, for which empirical scaling be...\n",
      "  - Pushed client training to loss that would have otherwise cost 6\\ compute budget...\n",
      "  - Performed original scaling studies on MoE models, for which empirical scaling be...\n",
      "  - Pushed client training to loss that would have otherwise cost 6\\ compute budget...\n",
      "  - Performed original scaling studies on MoE models, for which empirical scaling be...\n",
      "  - Pushed client training to loss that would have otherwise cost 6\\ compute budget...\n",
      "  - Performed original scaling studies on MoE models, for which empirical scaling be...\n",
      "  - Pushed client training to loss that would have otherwise cost 6\\ compute budget...\n",
      "  - Performed original scaling studies on MoE models for which empirical scaling beh...\n",
      "  - My hyperparameter specification enabled client's massive LLM pretraining to reac...\n",
      "  - Performed original scaling studies on MoE models for which empirical scaling beh...\n",
      "  - My hyperparameter specification enabled client's massive LLM pretraining to reac...\n",
      "  - Performed original scaling studies on MoE models for which empirical scaling beh...\n",
      "  - My hyperparameter specification enabled client's massive LLM pretraining to reac...\n",
      "  - Performed original scaling studies on MoE models for which empirical scaling beh...\n",
      "  - My hyperparameter specification enabled client's massive LLM pretraining to reac...\n",
      "  - Performed original scaling studies on MoE models, for which empirical scaling be...\n",
      "  - Pushed client training to a loss that would have otherwise cost 6 compute budget...\n"
     ]
    }
   ],
   "source": [
    "# Query items from specific project\n",
    "moe_items = db.query(\n",
    "    \"SELECT * FROM items WHERE project_name LIKE ?\",\n",
    "    (\"%Mixture of Experts%\",)\n",
    ")\n",
    "print(f\"Items from MoE project: {len(moe_items)}\")\n",
    "for item in moe_items:\n",
    "    print(f\"  - {item['item_text'][:80]}...\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Comparison\n",
    "\n",
    "When to use each interface?\n",
    "\n",
    "\n",
    "### Use ResumeDocumentArchive when:\n",
    "\n",
    "  ✓ Need to preserve section hierarchy\n",
    "  \n",
    "  ✓ Want markdown formatting (mode='markdown')\n",
    "  \n",
    "  ✓ Analyzing structure (table of contents, page layout)\n",
    "  \n",
    "  ✓ Iterating through sections in order\n",
    "  \n",
    "### Use ResumeDatabase when:\n",
    "\n",
    "  ✓ Searching across all resumes (WHERE, LIKE)\n",
    "  \n",
    "  ✓ Filtering by metadata (company, dates, type)\n",
    "  \n",
    "  ✓ Finding similar bullets or skills\n",
    "  \n",
    "  ✓ Fast queries without loading all resumes\n",
    "  \n",
    "  ✓ Persistent storage (no re-parsing needed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}