{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Page Structure Demonstration\n",
    "\n",
    "This notebook demonstrates complete single-page parsing with paracol structure.\n",
    "\n",
    "## What Step 4 Added\n",
    "\n",
    "- **Page-level data structures**: `Page`, `PageRegions`, `Column`, `Section`\n",
    "- **Paracol parsing**: `extract_page_regions()` finds `\\begin{paracol}{2}` and `\\switchcolumn`\n",
    "- **Type inference**: Automatically detects section types from LaTeX structure\n",
    "- **Page generation**: `generate_page()` creates complete paracol structure\n",
    "\n",
    "## Round-Trip Test\n",
    "\n",
    "We'll demonstrate: **LaTeX → YAML → LaTeX → YAML** and verify both round-trips produce identical results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Setup complete\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from archer.contexts.templating.converter import (\n",
    "    YAMLToLaTeXConverter,\n",
    "    LaTeXToYAMLConverter,\n",
    ")\n",
    "\n",
    "print(\"✅ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Load Original LaTeX\n",
    "\n",
    "Load the test LaTeX file with paracol structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original LaTeX:\n",
      "============================================================\n",
      "\\begin{paracol}{2}\n",
      "\n",
      "\\section*{Core Skills}\n",
      "   { \\setlength{\\baselineskip}{10pt} \\setlength{\\parskip}{7.5pt} \\scshape\n",
      "\n",
      "    Machine Learning\n",
      "\n",
      "    High-Performance\\\\Computing (HPC)\n",
      "\n",
      "    MLOps\n",
      "\n",
      "   }\n",
      "\n",
      "\\section*{Languages}\n",
      "\n",
      "    \\texttt{Python} | \\texttt{Bash} | \\texttt{C++}\n",
      "\n",
      "\\switchcolumn\n",
      "\n",
      "\\section*{Experience}\n",
      "\n",
      "    \\begin{itemizeAcademic}{Test Company}{Software Engineer}{City, ST}{2023 -- Present}\n",
      "\n",
      "        \\itemi Built scalable ML infrastructure\n",
      "\n",
      "        \\itemi Reduced latency by 50\\%\n",
      "\n",
      "    \\end{itemizeAcademic}\n",
      "\n",
      "\\end{paracol}\n",
      "\n",
      "============================================================\n",
      "\n",
      "Length: 527 characters\n"
     ]
    }
   ],
   "source": [
    "# Load original LaTeX\n",
    "latex_path = project_root / \"data/resume_archive/structured/single_page_test.tex\"\n",
    "original_latex = latex_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "print(\"Original LaTeX:\")\n",
    "print(\"=\" * 60)\n",
    "print(original_latex)\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nLength: {len(original_latex)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Parse LaTeX → Structured Dict (First Conversion)\n",
    "\n",
    "Parse the LaTeX into structured Python dict using `extract_page_regions()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed Structure (Python Dict):\n",
      "============================================================\n",
      "Top bar: show_professional_profile = True\n",
      "\n",
      "Left column sections: 2\n",
      "  1. Core Skills (skill_list_caps)\n",
      "  2. Languages (skill_list_pipes)\n",
      "\n",
      "Main column sections: 1\n",
      "  1. Experience (work_history)\n",
      "\n",
      "Bottom bar: None\n"
     ]
    }
   ],
   "source": [
    "# Parse LaTeX to structured format\n",
    "parser = LaTeXToYAMLConverter()\n",
    "page_regions_1 = parser.extract_page_regions(original_latex, page_number=1)\n",
    "\n",
    "print(\"Parsed Structure (Python Dict):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Display structure summary\n",
    "print(f\"Top bar: show_professional_profile = {page_regions_1['top']['show_professional_profile']}\")\n",
    "print(f\"\\nLeft column sections: {len(page_regions_1['left_column']['sections'])}\")\n",
    "for i, sect in enumerate(page_regions_1['left_column']['sections']):\n",
    "    print(f\"  {i+1}. {sect['name']} ({sect['type']})\")\n",
    "\n",
    "print(f\"\\nMain column sections: {len(page_regions_1['main_column']['sections'])}\")\n",
    "for i, sect in enumerate(page_regions_1['main_column']['sections']):\n",
    "    print(f\"  {i+1}. {sect['name']} ({sect['type']})\")\n",
    "\n",
    "print(f\"\\nBottom bar: {page_regions_1['bottom']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Convert Dict → YAML String\n",
    "\n",
    "Convert the structured dict to YAML format using OmegaConf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAML Representation:\n",
      "============================================================\n",
      "top:\n",
      "  show_professional_profile: true\n",
      "left_column:\n",
      "  sections:\n",
      "  - name: Core Skills\n",
      "    type: skill_list_caps\n",
      "    content:\n",
      "      list:\n",
      "      - Machine Learning\n",
      "      - High-Performance\\\\Computing (HPC)\n",
      "      - MLOps\n",
      "  - name: Languages\n",
      "    type: skill_list_pipes\n",
      "    content:\n",
      "      list:\n",
      "      - Python\n",
      "      - Bash\n",
      "      - C++\n",
      "main_column:\n",
      "  sections:\n",
      "  - name: Experience\n",
      "    type: work_history\n",
      "    subsections:\n",
      "    - type: work_experience\n",
      "      metadata:\n",
      "        company: Test Company\n",
      "        title: Software Engineer\n",
      "        location: City, ST\n",
      "        dates: 2023 -- Present\n",
      "      content:\n",
      "        bullets:\n",
      "        - text: Built scalable ML infrastructure\n",
      "        - text: Reduced latency by 50\\%\n",
      "bottom: null\n",
      "\n",
      "============================================================\n",
      "\n",
      "Length: 715 characters\n"
     ]
    }
   ],
   "source": [
    "# Convert to YAML\n",
    "yaml_conf_1 = OmegaConf.create(page_regions_1)\n",
    "yaml_str_1 = OmegaConf.to_yaml(yaml_conf_1)\n",
    "\n",
    "print(\"YAML Representation:\")\n",
    "print(\"=\" * 60)\n",
    "print(yaml_str_1)\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nLength: {len(yaml_str_1)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4: Generate LaTeX from Dict (Second Conversion)\n",
    "\n",
    "Generate LaTeX from the structured dict using `generate_page()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated LaTeX:\n",
      "============================================================\n",
      "\\begin{paracol}{2}\n",
      "\n",
      "\\section*{Core Skills}\n",
      "\n",
      "   { \\setlength{\\baselineskip}{10pt} \\setlength{\\parskip}{7.5pt} \\scshape\n",
      "\n",
      "    Machine Learning\n",
      "\n",
      "    High-Performance\\\\Computing (HPC)\n",
      "\n",
      "    MLOps\n",
      "\n",
      "   }\n",
      "\n",
      "\\section*{Languages}\n",
      "\n",
      "    \\texttt{Python} | \\texttt{Bash} | \\texttt{C++}\n",
      "\n",
      "\\switchcolumn\n",
      "\n",
      "\\section*{Experience}\n",
      "\n",
      "    \\begin{itemizeAcademic}{Test Company}{Software Engineer}{City, ST}{2023 -- Present}\n",
      "\n",
      "        \\itemi Built scalable ML infrastructure\n",
      "\n",
      "        \\itemi Reduced latency by 50\\%\n",
      "\n",
      "    \\end{itemizeAcademic}\n",
      "\n",
      "\n",
      "\\end{paracol}\n",
      "============================================================\n",
      "\n",
      "Length: 528 characters\n"
     ]
    }
   ],
   "source": [
    "# Generate LaTeX from parsed structure\n",
    "generator = YAMLToLaTeXConverter()\n",
    "generated_latex = generator.generate_page(page_regions_1)\n",
    "\n",
    "print(\"Generated LaTeX:\")\n",
    "print(\"=\" * 60)\n",
    "print(generated_latex)\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nLength: {len(generated_latex)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 5: Parse Generated LaTeX → Dict Again (Third Conversion)\n",
    "\n",
    "Parse the generated LaTeX back into structured dict to complete the round-trip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round-trip Parsed Structure:\n",
      "============================================================\n",
      "Top bar: show_professional_profile = True\n",
      "\n",
      "Left column sections: 2\n",
      "  1. Core Skills (skill_list_caps)\n",
      "  2. Languages (skill_list_pipes)\n",
      "\n",
      "Main column sections: 1\n",
      "  1. Experience (work_history)\n"
     ]
    }
   ],
   "source": [
    "# Parse generated LaTeX back to structure\n",
    "page_regions_2 = parser.extract_page_regions(generated_latex, page_number=1)\n",
    "\n",
    "print(\"Round-trip Parsed Structure:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Display structure summary\n",
    "print(f\"Top bar: show_professional_profile = {page_regions_2['top']['show_professional_profile']}\")\n",
    "print(f\"\\nLeft column sections: {len(page_regions_2['left_column']['sections'])}\")\n",
    "for i, sect in enumerate(page_regions_2['left_column']['sections']):\n",
    "    print(f\"  {i+1}. {sect['name']} ({sect['type']})\")\n",
    "\n",
    "print(f\"\\nMain column sections: {len(page_regions_2['main_column']['sections'])}\")\n",
    "for i, sect in enumerate(page_regions_2['main_column']['sections']):\n",
    "    print(f\"  {i+1}. {sect['name']} ({sect['type']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: Convert Second Dict → YAML String\n",
    "\n",
    "Convert the round-trip dict to YAML for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round-trip YAML Representation:\n",
      "============================================================\n",
      "top:\n",
      "  show_professional_profile: true\n",
      "left_column:\n",
      "  sections:\n",
      "  - name: Core Skills\n",
      "    type: skill_list_caps\n",
      "    content:\n",
      "      list:\n",
      "      - Machine Learning\n",
      "      - High-Performance\\\\Computing (HPC)\n",
      "      - MLOps\n",
      "  - name: Languages\n",
      "    type: skill_list_pipes\n",
      "    content:\n",
      "      list:\n",
      "      - Python\n",
      "      - Bash\n",
      "      - C++\n",
      "main_column:\n",
      "  sections:\n",
      "  - name: Experience\n",
      "    type: work_history\n",
      "    subsections:\n",
      "    - type: work_experience\n",
      "      metadata:\n",
      "        company: Test Company\n",
      "        title: Software Engineer\n",
      "        location: City, ST\n",
      "        dates: 2023 -- Present\n",
      "      content:\n",
      "        bullets:\n",
      "        - text: Built scalable ML infrastructure\n",
      "        - text: Reduced latency by 50\\%\n",
      "bottom: null\n",
      "\n",
      "============================================================\n",
      "\n",
      "Length: 715 characters\n"
     ]
    }
   ],
   "source": [
    "# Convert round-trip structure to YAML\n",
    "yaml_conf_2 = OmegaConf.create(page_regions_2)\n",
    "yaml_str_2 = OmegaConf.to_yaml(yaml_conf_2)\n",
    "\n",
    "print(\"Round-trip YAML Representation:\")\n",
    "print(\"=\" * 60)\n",
    "print(yaml_str_2)\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nLength: {len(yaml_str_2)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Validation: Compare Original and Round-Trip Structures\n",
    "\n",
    "Now we'll validate that the structures are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structure Comparison:\n",
      "============================================================\n",
      "✅ SUCCESS: Structures are IDENTICAL\n",
      "\n",
      "LaTeX → Dict → LaTeX → Dict produces identical structure\n"
     ]
    }
   ],
   "source": [
    "# Compare the two dicts\n",
    "print(\"Structure Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check if dicts are equal\n",
    "if page_regions_1 == page_regions_2:\n",
    "    print(\"✅ SUCCESS: Structures are IDENTICAL\")\n",
    "    print(\"\\nLaTeX → Dict → LaTeX → Dict produces identical structure\")\n",
    "else:\n",
    "    print(\"❌ FAILURE: Structures differ\")\n",
    "    print(\"\\nDifferences found - investigating...\")\n",
    "    \n",
    "    # Check each component\n",
    "    if page_regions_1['top'] != page_regions_2['top']:\n",
    "        print(\"  - Top bar differs\")\n",
    "    if page_regions_1['left_column'] != page_regions_2['left_column']:\n",
    "        print(\"  - Left column differs\")\n",
    "    if page_regions_1['main_column'] != page_regions_2['main_column']:\n",
    "        print(\"  - Main column differs\")\n",
    "    if page_regions_1['bottom'] != page_regions_2['bottom']:\n",
    "        print(\"  - Bottom bar differs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Detailed Content Validation\n",
    "\n",
    "Let's verify that section content is preserved correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content Validation:\n",
      "============================================================\n",
      "Core Skills section:\n",
      "  Original items: 3\n",
      "  Round-trip items: 3\n",
      "  ✅ Lists are identical\n",
      "\n",
      "Languages section:\n",
      "  Original items: 3\n",
      "  Round-trip items: 3\n",
      "  ✅ Lists are identical\n",
      "\n",
      "Experience section:\n",
      "  Original subsections: 1\n",
      "  Round-trip subsections: 1\n",
      "  Original company: Test Company\n",
      "  Round-trip company: Test Company\n",
      "  Original bullets: 2\n",
      "  Round-trip bullets: 2\n",
      "  ✅ Work experience is identical\n"
     ]
    }
   ],
   "source": [
    "print(\"Content Validation:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check Core Skills content\n",
    "core_skills_1 = page_regions_1['left_column']['sections'][0]\n",
    "core_skills_2 = page_regions_2['left_column']['sections'][0]\n",
    "\n",
    "print(\"Core Skills section:\")\n",
    "print(f\"  Original items: {len(core_skills_1['content']['list'])}\")\n",
    "print(f\"  Round-trip items: {len(core_skills_2['content']['list'])}\")\n",
    "if core_skills_1['content']['list'] == core_skills_2['content']['list']:\n",
    "    print(\"  ✅ Lists are identical\")\n",
    "else:\n",
    "    print(\"  ❌ Lists differ\")\n",
    "    print(f\"    Original: {core_skills_1['content']['list']}\")\n",
    "    print(f\"    Round-trip: {core_skills_2['content']['list']}\")\n",
    "\n",
    "# Check Languages content\n",
    "languages_1 = page_regions_1['left_column']['sections'][1]\n",
    "languages_2 = page_regions_2['left_column']['sections'][1]\n",
    "\n",
    "print(\"\\nLanguages section:\")\n",
    "print(f\"  Original items: {len(languages_1['content']['list'])}\")\n",
    "print(f\"  Round-trip items: {len(languages_2['content']['list'])}\")\n",
    "if languages_1['content']['list'] == languages_2['content']['list']:\n",
    "    print(\"  ✅ Lists are identical\")\n",
    "else:\n",
    "    print(\"  ❌ Lists differ\")\n",
    "\n",
    "# Check Experience content\n",
    "experience_1 = page_regions_1['main_column']['sections'][0]\n",
    "experience_2 = page_regions_2['main_column']['sections'][0]\n",
    "\n",
    "print(\"\\nExperience section:\")\n",
    "print(f\"  Original subsections: {len(experience_1['subsections'])}\")\n",
    "print(f\"  Round-trip subsections: {len(experience_2['subsections'])}\")\n",
    "\n",
    "work_exp_1 = experience_1['subsections'][0]\n",
    "work_exp_2 = experience_2['subsections'][0]\n",
    "\n",
    "print(f\"  Original company: {work_exp_1['metadata']['company']}\")\n",
    "print(f\"  Round-trip company: {work_exp_2['metadata']['company']}\")\n",
    "print(f\"  Original bullets: {len(work_exp_1['content']['bullets'])}\")\n",
    "print(f\"  Round-trip bullets: {len(work_exp_2['content']['bullets'])}\")\n",
    "\n",
    "if work_exp_1 == work_exp_2:\n",
    "    print(\"  ✅ Work experience is identical\")\n",
    "else:\n",
    "    print(\"  ❌ Work experience differs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## YAML String Comparison\n",
    "\n",
    "Compare the two YAML strings (they should be identical)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAML String Comparison:\n",
      "============================================================\n",
      "✅ SUCCESS: YAML strings are IDENTICAL\n",
      "\n",
      "No differences in YAML representation\n"
     ]
    }
   ],
   "source": [
    "print(\"YAML String Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if yaml_str_1 == yaml_str_2:\n",
    "    print(\"✅ SUCCESS: YAML strings are IDENTICAL\")\n",
    "    print(\"\\nNo differences in YAML representation\")\n",
    "else:\n",
    "    print(\"❌ FAILURE: YAML strings differ\")\n",
    "    print(f\"\\nOriginal YAML length: {len(yaml_str_1)}\")\n",
    "    print(f\"Round-trip YAML length: {len(yaml_str_2)}\")\n",
    "    \n",
    "    # Show character-by-character diff for debugging\n",
    "    import difflib\n",
    "    diff = difflib.unified_diff(\n",
    "        yaml_str_1.splitlines(keepends=True),\n",
    "        yaml_str_2.splitlines(keepends=True),\n",
    "        fromfile='original_yaml',\n",
    "        tofile='roundtrip_yaml',\n",
    "        lineterm=''\n",
    "    )\n",
    "    print(\"\\nDifferences:\")\n",
    "    print(''.join(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## LaTeX Comparison (Structural)\n",
    "\n",
    "Compare original LaTeX with generated LaTeX. Note: Whitespace/formatting may differ, but structure should be identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaTeX Comparison:\n",
      "============================================================\n",
      "  ✅ paracol environment: present in both\n",
      "  ✅ column switch: present in both\n",
      "  ✅ paracol close: present in both\n",
      "  ✅ Core Skills section: present in both\n",
      "  ✅ Languages section: present in both\n",
      "  ✅ Experience section: present in both\n",
      "  ✅ work experience environment: present in both\n",
      "\n",
      "✅ All structural elements present in generated LaTeX\n"
     ]
    }
   ],
   "source": [
    "print(\"LaTeX Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check key structural elements\n",
    "checks = [\n",
    "    (r\"\\begin{paracol}{2}\", \"paracol environment\"),\n",
    "    (r\"\\switchcolumn\", \"column switch\"),\n",
    "    (r\"\\end{paracol}\", \"paracol close\"),\n",
    "    (r\"\\section*{Core Skills}\", \"Core Skills section\"),\n",
    "    (r\"\\section*{Languages}\", \"Languages section\"),\n",
    "    (r\"\\section*{Experience}\", \"Experience section\"),\n",
    "    (r\"\\begin{itemizeAcademic}\", \"work experience environment\"),\n",
    "]\n",
    "\n",
    "all_present = True\n",
    "for pattern, description in checks:\n",
    "    in_original = pattern in original_latex\n",
    "    in_generated = pattern in generated_latex\n",
    "    \n",
    "    if in_original and in_generated:\n",
    "        print(f\"  ✅ {description}: present in both\")\n",
    "    elif not in_original and not in_generated:\n",
    "        print(f\"  ✅ {description}: absent in both\")\n",
    "    else:\n",
    "        print(f\"  ❌ {description}: MISMATCH\")\n",
    "        print(f\"     Original: {in_original}, Generated: {in_generated}\")\n",
    "        all_present = False\n",
    "\n",
    "if all_present:\n",
    "    print(\"\\n✅ All structural elements present in generated LaTeX\")\n",
    "else:\n",
    "    print(\"\\n❌ Some structural elements missing or mismatched\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Final Summary\n",
    "\n",
    "Overall validation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL VALIDATION RESULTS\n",
      "============================================================\n",
      "\n",
      "1. Dict comparison: ✅ PASS\n",
      "2. YAML comparison: ✅ PASS\n",
      "\n",
      "============================================================\n",
      "🎉 COMPLETE SUCCESS 🎉\n",
      "============================================================\n",
      "\n",
      "LaTeX → YAML → LaTeX → YAML produces identical results\n",
      "\n",
      "Step 4 validation: PASSED\n",
      "\n",
      "Page structure parsing works correctly:\n",
      "  ✅ Paracol environment detected\n",
      "  ✅ Column separation preserved\n",
      "  ✅ Section types inferred correctly\n",
      "  ✅ Section content preserved\n",
      "  ✅ Complete round-trip fidelity\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL VALIDATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculate success\n",
    "dict_match = (page_regions_1 == page_regions_2)\n",
    "yaml_match = (yaml_str_1 == yaml_str_2)\n",
    "\n",
    "print(f\"\\n1. Dict comparison: {'✅ PASS' if dict_match else '❌ FAIL'}\")\n",
    "print(f\"2. YAML comparison: {'✅ PASS' if yaml_match else '❌ FAIL'}\")\n",
    "\n",
    "if dict_match and yaml_match:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"🎉 COMPLETE SUCCESS 🎉\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nLaTeX → YAML → LaTeX → YAML produces identical results\")\n",
    "    print(\"\\nStep 4 validation: PASSED\")\n",
    "    print(\"\\nPage structure parsing works correctly:\")\n",
    "    print(\"  ✅ Paracol environment detected\")\n",
    "    print(\"  ✅ Column separation preserved\")\n",
    "    print(\"  ✅ Section types inferred correctly\")\n",
    "    print(\"  ✅ Section content preserved\")\n",
    "    print(\"  ✅ Complete round-trip fidelity\")\n",
    "else:\n",
    "    print(\"\\n❌ VALIDATION FAILED - See differences above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Optional: Save Files for Manual Inspection\n",
    "\n",
    "Save the generated LaTeX to a file so you can manually diff it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated LaTeX saved to: /home/sean/ARCHER/data/resume_archive/structured/single_page_test_generated.tex\n",
      "\n",
      "To manually diff:\n",
      "  diff data/resume_archive/structured/single_page_test.tex \\\n",
      "       data/resume_archive/structured/single_page_test_generated.tex\n"
     ]
    }
   ],
   "source": [
    "# Save generated LaTeX for manual inspection\n",
    "output_path = project_root / \"data/resume_archive/structured/single_page_test_generated.tex\"\n",
    "output_path.write_text(generated_latex, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Generated LaTeX saved to: {output_path}\")\n",
    "print(f\"\\nTo manually diff:\")\n",
    "print(f\"  diff data/resume_archive/structured/single_page_test.tex \\\\\")\n",
    "print(f\"       data/resume_archive/structured/single_page_test_generated.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
