{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Data Structure Demo\n",
    "\n",
    "This notebook demonstrates the `ResumeDocument` and `ResumeDocumentArchive` classes from `archer.contexts.templating.resume_data_structure`.\n",
    "\n",
    "These classes provide a **simplified interface designed for the targeting context** to work with resume data by stripping away LaTeX formatting and layout metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from archer.contexts.templating.resume_data_structure import (\n",
    "    ResumeDocument,\n",
    "    ResumeDocumentArchive,\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "RESUME_ARCHIVE_PATH = Path(os.getenv(\"RESUME_ARCHIVE_PATH\"))\n",
    "\n",
    "# Pick a sample resume\n",
    "sample_yaml = RESUME_ARCHIVE_PATH / \"structured\" / \"Res_ACMECorp.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Without ResumeDocument (OmegaConf)\n",
    "\n",
    "Let's see what working directly with the YAML looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load with OmegaConf\n",
    "yaml_data = OmegaConf.load(sample_yaml)\n",
    "yaml_dict = OmegaConf.to_container(yaml_data, resolve=True)\n",
    "\n",
    "print(\"Top-level keys:\")\n",
    "print(list(yaml_dict.keys()))\n",
    "print(\"\\nDocument keys:\")\n",
    "print(list(yaml_dict[\"document\"].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Work Experience Directly from yaml (Without ResumeDocument)\n",
    "\n",
    "Notice how deeply nested and complex the structure is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate the complex nested structure\n",
    "doc = yaml_dict[\"document\"]\n",
    "\n",
    "# Find work experience sections\n",
    "work_experiences = []\n",
    "for page in doc.get(\"pages\", []):\n",
    "    for region_name, region_data in page.get(\"regions\", {}).items():\n",
    "        if region_data and \"sections\" in region_data:\n",
    "            for section in region_data[\"sections\"]:\n",
    "                # Check for nested subsections (work_history contains work_experience)\n",
    "                if \"subsections\" in section:\n",
    "                    for subsection in section[\"subsections\"]:\n",
    "                        if subsection.get(\"type\") == \"work_experience\":\n",
    "                            work_experiences.append(subsection)\n",
    "\n",
    "print(f\"Found {len(work_experiences)} work experiences\\n\")\n",
    "\n",
    "# Get first work experience\n",
    "first_work = work_experiences[0]\n",
    "print(\"Company:\", first_work[\"metadata\"][\"company\"])\n",
    "print(\"Title:\", first_work[\"metadata\"][\"title\"])\n",
    "print(\"Dates:\", first_work[\"metadata\"][\"dates\"])\n",
    "print(\"\\nProjects:\")\n",
    "for proj in first_work[\"content\"][\"projects\"][:2]:\n",
    "    # Note: project names still have LaTeX formatting\n",
    "    print(f\"  - {proj['metadata']['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Skills (Without ResumeDocument)\n",
    "\n",
    "Also requires manual navigation and LaTeX cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find skill sections\n",
    "skill_sections = []\n",
    "for page in doc.get(\"pages\", []):\n",
    "    for region_name, region_data in page.get(\"regions\", {}).items():\n",
    "        if region_data and \"sections\" in region_data:\n",
    "            for section in region_data[\"sections\"]:\n",
    "                if section.get(\"type\") in (\"skill_list_caps\", \"skill_list_pipes\", \"skill_categories\"):\n",
    "                    skill_sections.append(section)\n",
    "\n",
    "print(f\"Found {len(skill_sections)} skill sections\\n\")\n",
    "\n",
    "# Get first skill section\n",
    "first_skills = skill_sections[0]\n",
    "print(f\"Section: {first_skills['name']}\")\n",
    "print(\"Skills (raw - with LaTeX):\")\n",
    "for skill in first_skills[\"content\"][\"items\"][:5]:\n",
    "    print(f\"  - {skill}\")\n",
    "\n",
    "# Would need to manually clean LaTeX formatting..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Problems:\n",
    "\n",
    "1. **Complex navigation** - Multiple nested loops to find sections\n",
    "2. **Mixed with formatting** - Colors, spacing, LaTeX commands mixed with content\n",
    "3. **No text extraction** - Have to manually build plaintext\n",
    "4. **Lots of boilerplate** - Same navigation code repeated everywhere\n",
    "\n",
    "---\n",
    "\n",
    "## Part 2: ResumeDocument\n",
    "\n",
    "Now let's see the simplified interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load with ResumeDocument\n",
    "doc = ResumeDocument(sample_yaml)\n",
    "\n",
    "print(f\"Name: {doc.name}\")\n",
    "print(f\"Title: {doc.professional_title}\")\n",
    "print(f\"Filename: {doc.filename}\")\n",
    "print(f\"Date: {doc.date}\")\n",
    "print(f\"Total sections: {len(doc.sections)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "Get a formatted overview of all sections with one property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All sections:\")\n",
    "for i, section in enumerate(doc.sections, 1):\n",
    "    print(f\"{i}. {section.name} ({section.section_type})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Work Experience (New Way)\n",
    "\n",
    "Work experiences are now grouped in `work_history` sections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find work_history sections\n",
    "work_history_sections = [s for s in doc.sections if s.section_type == \"work_history\"]\n",
    "\n",
    "print(f\"Found {len(work_history_sections)} work history sections\\n\")\n",
    "\n",
    "# Get first work_history section\n",
    "first_history = work_history_sections[1]\n",
    "print(f\"Section: {first_history.name}\")\n",
    "print(f\"Number of work experiences: {len(first_history.data['subsections'])}\\n\")\n",
    "\n",
    "# Access first work experience within the section\n",
    "first_work = first_history.data['subsections'][0]\n",
    "\n",
    "# Structured data access\n",
    "print(f\"Company: {first_work['company']}\")\n",
    "print(f\"Title: {first_work['title']}\")\n",
    "print(f\"Dates: {first_work['dates']}\")\n",
    "print(f\"Location: {first_work['location']}\")\n",
    "\n",
    "# Show top-level bullets\n",
    "print(f\"\\nTop-level bullets ({len(first_work.get('bullets', []))}):\\n\")\n",
    "for i, bullet in enumerate(first_work.get('bullets', [])[:3], 1):\n",
    "    print(f\"{i}. {bullet[:100]}...\")\n",
    "if len(first_work.get('bullets', [])) > 3:\n",
    "    print(f\"   ... and {len(first_work.get('bullets', [])) - 3} more\")\n",
    "\n",
    "# Show projects\n",
    "print(f\"\\nProjects ({len(first_work['projects'])}):\\n\")\n",
    "\n",
    "for proj in first_work['projects']:\n",
    "    print(f\"üìå {proj['name']}\")\n",
    "    print(f\"   Bullets: {len(proj['bullets'])}\")\n",
    "    if proj['bullets']:\n",
    "        print(f\"   First bullet: {proj['bullets'][0][:80]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Skills (using ResumeDocument)\n",
    "\n",
    "Clean, LaTeX-free text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find skill sections\n",
    "skill_sections = [\n",
    "    s for s in doc.sections \n",
    "    if s.section_type in (\"skill_list_caps\", \"skill_list_pipes\", \"skill_categories\")\n",
    "]\n",
    "\n",
    "print(f\"Found {len(skill_sections)} skill sections\\n\")\n",
    "\n",
    "for section in skill_sections:\n",
    "    print(f\"üìã {section.name} ({section.section_type}):\")\n",
    "    \n",
    "    # Handle flat skill lists (unified structure with \"items\")\n",
    "    if section.section_type in (\"skill_list_caps\", \"skill_list_pipes\"):\n",
    "        for skill in section.data['items'][:5]:\n",
    "            print(f\"   ‚Ä¢ {skill}\")\n",
    "        if len(section.data['items']) > 5:\n",
    "            print(f\"   ... and {len(section.data['items']) - 5} more\")\n",
    "    \n",
    "    # Handle categorized skills (conatainer with subsections)\n",
    "    elif section.section_type == \"skill_categories\":\n",
    "        for category in section.data['subsections'][:3]:  # Show first 3 categories\n",
    "            print(f\"   üìÅ {category['name']}:\")\n",
    "            for skill in category['items'][:3]:  # Show first 3 skills per category\n",
    "                print(f\"      ‚Ä¢ {skill}\")\n",
    "            if len(category['items']) > 3:\n",
    "                print(f\"      ... and {len(category['items']) - 3} more\")\n",
    "        if len(section.data['subsections']) > 3:\n",
    "            print(f\"   ... and {len(section.data['subsections']) - 3} more categories\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markdown Text Property\n",
    "\n",
    "Each section has a `.text` property that formats structured data into **markdown** (not plaintext!).\n",
    "\n",
    "This is perfect for LLM consumption since markdown is very on-distribution for language models.\n",
    "\n",
    "**Key feature:** It's lazy-evaluated and cached!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a work_history section\n",
    "work_section = work_history_sections[0]\n",
    "\n",
    "# Check if text is cached\n",
    "print(f\"Text cached initially: {work_section._text_cache is not None}\")\n",
    "\n",
    "# Access text property (triggers formatting)\n",
    "text = work_section.text\n",
    "\n",
    "print(f\"Text cached after access: {work_section._text_cache is not None}\")\n",
    "print(f\"\\nMarkdown preview (first 700 chars):\\n\")\n",
    "print(text[:700])\n",
    "print(\"...\")\n",
    "\n",
    "# Show markdown structure\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Notice the markdown formatting:\")\n",
    "print(\"  - ## for section headers (e.g., 'Experience')\")\n",
    "print(\"  - ### for company names\")\n",
    "print(\"  - **bold** for job titles\")\n",
    "print(\"  - *italic* for dates\")\n",
    "print(\"  - #### for project headers\")\n",
    "print(\"  - - for bullet points\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get All Text\n",
    "\n",
    "Combine all sections into one searchable markdown document.\n",
    "\n",
    "**Page breaks:** The `---` markdown separator appears between pages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = doc.get_all_text()\n",
    "\n",
    "print(f\"Total text length: {len(all_text)} characters\")\n",
    "print(f\"Total words (approx): {len(all_text.split())}\")\n",
    "\n",
    "# Check page numbers\n",
    "page_numbers = sorted(set(s.page_number for s in doc.sections))\n",
    "print(f\"\\nPages in document: {page_numbers}\")\n",
    "\n",
    "# Count actual page breaks (not dates that use ---)\n",
    "page_break_count = all_text.count('\\n\\n---\\n\\n')\n",
    "print(f\"Page break markers: {page_break_count}\")\n",
    "\n",
    "print(f\"\\nSearching for 'Machine Learning'...\")\n",
    "# Simple text search\n",
    "count = all_text.lower().count('machine learning')\n",
    "print(f\"Found {count} occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sections by page\n",
    "print(\"Sections by page:\\n\")\n",
    "for page in sorted(set(s.page_number for s in doc.sections)):\n",
    "    page_sections = [s for s in doc.sections if s.page_number == page]\n",
    "    print(f\"Page {page}:\")\n",
    "    for section in page_sections:\n",
    "        print(f\"  - {section.name} ({section.section_type})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: ResumeDocumentArchive\n",
    "\n",
    "Load multiple resumes at once with error handling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize archive\n",
    "archive = ResumeDocumentArchive(RESUME_ARCHIVE_PATH)\n",
    "\n",
    "import warnings\n",
    "yaml_files = sorted(archive.structured_path.glob(\"*.yaml\"))\n",
    "\n",
    "i = 0\n",
    "errors = []\n",
    "for yaml_file in yaml_files:\n",
    "    try:\n",
    "        doc = ResumeDocument(yaml_file, mode=\"plaintext\")\n",
    "        i += 1\n",
    "    except Exception as e:\n",
    "        errors.append((yaml_file.name, str(e)))\n",
    "if errors:\n",
    "    error_summary = \"\\n\".join(f\"  - {name}: {error}\" for name, error in errors)\n",
    "    warnings.warn(\n",
    "        f\"Failed to load {len(errors)} YAML file(s):\\n{error_summary}\",\n",
    "        UserWarning\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all pre-converted YAMLs\n",
    "documents = archive.load(mode=\"available\")\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "print(f\"\\nFirst 10 filenames:\")\n",
    "for doc in documents[:10]:\n",
    "    print(f\"  ‚Ä¢ {doc.filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the Archive\n",
    "\n",
    "Now we can easily analyze all resumes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count section types across all resumes\n",
    "section_type_counts = {}\n",
    "\n",
    "for doc in documents:\n",
    "    for section in doc.sections:\n",
    "        section_type_counts[section.section_type] = section_type_counts.get(section.section_type, 0) + 1\n",
    "\n",
    "print(\"Section types across all resumes:\")\n",
    "for stype, count in sorted(section_type_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {stype}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total work experiences across all work_history sections per resume\n",
    "work_exp_counts = []\n",
    "for doc in documents:\n",
    "    count = sum(\n",
    "        len(s.data.get('subsections', [])) \n",
    "        for s in doc.sections \n",
    "        if s.section_type == \"work_history\"\n",
    "    )\n",
    "    work_exp_counts.append(count)\n",
    "\n",
    "print(f\"Average work experiences per resume: {sum(work_exp_counts) / len(work_exp_counts):.1f}\")\n",
    "print(f\"Min: {min(work_exp_counts)}, Max: {max(work_exp_counts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching Across All Resumes\n",
    "\n",
    "Find resumes mentioning specific technologies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_resumes_with_keyword(documents, keyword):\n",
    "    \"\"\"Find resumes containing a keyword.\"\"\"\n",
    "    matches = []\n",
    "    for doc in documents:\n",
    "        text = doc.get_all_text().lower()\n",
    "        if keyword.lower() in text:\n",
    "            matches.append(doc)\n",
    "    return matches\n",
    "\n",
    "# Search for different keywords\n",
    "keywords = [\"pytorch\", \"kubernetes\", \"llm\", \"hpc\", \"machine learning\", \"tensorflow\", \"docker\"]\n",
    "\n",
    "print(\"Keyword search results:\\n\")\n",
    "for keyword in keywords:\n",
    "    matches = find_resumes_with_keyword(documents, keyword)\n",
    "    print(f\"'{keyword}': {len(matches)} resumes ({len(matches)/len(documents)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Key Advantages Summary\n",
    "\n",
    "### OmegaConf\n",
    "‚ùå Complex nested navigation  \n",
    "‚ùå Mixed with formatting metadata  \n",
    "‚ùå LaTeX commands in text  \n",
    "‚ùå Boilerplate code for every operation  \n",
    "‚ùå Hard to search/analyze  \n",
    "\n",
    "### ResumeDocument\n",
    "‚úÖ Flat, direct section access  \n",
    "‚úÖ Content only (no formatting)  \n",
    "‚úÖ **Markdown output** (great for LLM comprehension)  \n",
    "‚úÖ LaTeX automatically converted to markdown  \n",
    "‚úÖ **Page breaks preserved** (`---` separators between pages)  \n",
    "‚úÖ **Professional profile included** at the top  \n",
    "‚úÖ **Table of contents property** for quick overview  \n",
    "‚úÖ **Region tracking** (left column vs main column)  \n",
    "‚úÖ **Hierarchical structure preserved** (work_history contains multiple work experiences)  \n",
    "‚úÖ Simple, reusable API  \n",
    "‚úÖ Easy search and analysis  \n",
    "‚úÖ Batch operations with error handling  \n",
    "\n",
    "### Markdown Formatting\n",
    "\n",
    "The `.text` property returns markdown with:\n",
    "- `#` header for professional profile (name | brand)\n",
    "- `##` headers for section headings (e.g., \"Experience\", \"Education\")\n",
    "- `###` headers for companies/institutions\n",
    "- `####` headers for projects\n",
    "- **Bold** for emphasis (from `\\textbf{}`, `\\coloremph{}`)\n",
    "- *Italic* usually for dates (from `\\textit{}`)\n",
    "- `-` for bullet points\n",
    "- `` `code` `` for `\\texttt{}` (usually software names)\n",
    "- `---` page breaks between pages\n",
    "\n",
    "This hierarchy prevents duplicate section headers and groups related work experiences together!\n",
    "\n",
    "This is *on-distribution* for LLMs, making it perfect for:\n",
    "- Prompting language models\n",
    "- Semantic search with embeddings\n",
    "- Content relevance scoring\n",
    "- Automated analysis\n",
    "\n",
    "### Perfect for Targeting Context ‚úÖ\n",
    "\n",
    "The Targeting context can now:\n",
    "- Get quick resume overview with `doc.table_of_contents`\n",
    "- Search historical resumes for relevant content\n",
    "- Score sections by relevance to job description\n",
    "- Find similar past applications\n",
    "- Extract bullets matching specific criteria\n",
    "- Pass markdown directly to LLMs for decision-making\n",
    "- Preserve page structure for layout decisions\n",
    "- Track which sections are in left vs main column\n",
    "- Access grouped work experiences within work_history sections\n",
    "- All without worrying about LaTeX formatting!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
